// Code generated by cudago. Edit at your own risk.
package cudago

import (
    "github.com/InternatBlackhole/cudago/cuda"
	"unsafe"
)


//here just to force usage of unsafe package
var __urejanje_nl_useless_var__ unsafe.Pointer = nil

const (
	KeyUrejanje_nl = "urejanje_nl"
)


type bitonicsortstartArgs struct {
    a uintptr
    len int32

}
type bitonicsortmiddleArgs struct {
    a uintptr
    len int32
    k int32
    j int32

}
type bitonicsortfinishArgs struct {
    a uintptr
    len int32
    k int32

}

/*var (
    bitonicsortstartArgs = bitonicsortstartArgs{}

    bitonicsortmiddleArgs = bitonicsortmiddleArgs{}

    bitonicsortfinishArgs = bitonicsortfinishArgs{}

)*/







func BitonicSortStart(grid, block cuda.Dim3, a uintptr, len int32) error {
	err := autoloadLib_urejanje_nl()
	if err != nil {
		return err
	}
	kern, err := getKernel("urejanje_nl", "bitonicSortStart")
	if err != nil {
		return err
	}
	
	params := bitonicsortstartArgs{
	    a: a,
	    len: len,
	
	}
	
	return kern.Launch(grid, block, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len))
}

func BitonicSortStartEx(grid, block cuda.Dim3, sharedMem uint64, stream *cuda.Stream, a uintptr, len int32) error {
	err := autoloadLib_urejanje_nl()
	if err != nil {
		return err
	}
	kern, err := getKernel("urejanje_nl", "bitonicSortStart")
	if err != nil {
		return err
	}
	
	params := bitonicsortstartArgs{
	    a: a,
	    len: len,
	
	}
	
	return kern.LaunchEx(grid, block, sharedMem, stream, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len))
}




func BitonicSortMiddle(grid, block cuda.Dim3, a uintptr, len int32, k int32, j int32) error {
	err := autoloadLib_urejanje_nl()
	if err != nil {
		return err
	}
	kern, err := getKernel("urejanje_nl", "bitonicSortMiddle")
	if err != nil {
		return err
	}
	
	params := bitonicsortmiddleArgs{
	    a: a,
	    len: len,
	    k: k,
	    j: j,
	
	}
	
	return kern.Launch(grid, block, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len), unsafe.Pointer(&params.k), unsafe.Pointer(&params.j))
}

func BitonicSortMiddleEx(grid, block cuda.Dim3, sharedMem uint64, stream *cuda.Stream, a uintptr, len int32, k int32, j int32) error {
	err := autoloadLib_urejanje_nl()
	if err != nil {
		return err
	}
	kern, err := getKernel("urejanje_nl", "bitonicSortMiddle")
	if err != nil {
		return err
	}
	
	params := bitonicsortmiddleArgs{
	    a: a,
	    len: len,
	    k: k,
	    j: j,
	
	}
	
	return kern.LaunchEx(grid, block, sharedMem, stream, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len), unsafe.Pointer(&params.k), unsafe.Pointer(&params.j))
}




func BitonicSortFinish(grid, block cuda.Dim3, a uintptr, len int32, k int32) error {
	err := autoloadLib_urejanje_nl()
	if err != nil {
		return err
	}
	kern, err := getKernel("urejanje_nl", "bitonicSortFinish")
	if err != nil {
		return err
	}
	
	params := bitonicsortfinishArgs{
	    a: a,
	    len: len,
	    k: k,
	
	}
	
	return kern.Launch(grid, block, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len), unsafe.Pointer(&params.k))
}

func BitonicSortFinishEx(grid, block cuda.Dim3, sharedMem uint64, stream *cuda.Stream, a uintptr, len int32, k int32) error {
	err := autoloadLib_urejanje_nl()
	if err != nil {
		return err
	}
	kern, err := getKernel("urejanje_nl", "bitonicSortFinish")
	if err != nil {
		return err
	}
	
	params := bitonicsortfinishArgs{
	    a: a,
	    len: len,
	    k: k,
	
	}
	
	return kern.LaunchEx(grid, block, sharedMem, stream, unsafe.Pointer(&params.a), unsafe.Pointer(&params.len), unsafe.Pointer(&params.k))
}



var loaded_urejanje_nl = false


func autoloadLib_urejanje_nl() error {
	if loaded_urejanje_nl {
		return nil
	}
	err := InitLibrary([]byte(Urejanje_nl_ptxCode), "urejanje_nl")
	if err != nil {
		return err
	}
	loaded_urejanje_nl = true
	return nil
}

const Urejanje_nl_ptxCode = `//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34431801
// Cuda compilation tools, release 12.6, V12.6.20
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_52
.address_size 64

	// .globl	bitonicSortStart
.extern .shared .align 16 .b8 as[];

.visible .entry bitonicSortStart(
	.param .u64 bitonicSortStart_param_0,
	.param .u32 bitonicSortStart_param_1
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<37>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd7, [bitonicSortStart_param_0];
	ld.param.u32 	%r14, [bitonicSortStart_param_1];
	cvta.to.global.u64 	%rd8, %rd7;
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r2, %r1, 1;
	mov.u32 	%r3, %ctaid.x;
	mul.lo.s32 	%r15, %r2, %r3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r16, %r15, %r4;
	mul.wide.u32 	%rd9, %r16, 4;
	add.s64 	%rd1, %rd8, %rd9;
	ld.global.u32 	%r17, [%rd1];
	mul.wide.u32 	%rd10, %r4, 4;
	mov.u64 	%rd11, as;
	add.s64 	%rd2, %rd11, %rd10;
	st.shared.u32 	[%rd2], %r17;
	add.s32 	%r18, %r4, %r1;
	add.s32 	%r19, %r18, %r15;
	mul.wide.u32 	%rd12, %r19, 4;
	add.s64 	%rd3, %rd8, %rd12;
	ld.global.u32 	%r20, [%rd3];
	mul.wide.u32 	%rd13, %r18, 4;
	add.s64 	%rd4, %rd11, %rd13;
	st.shared.u32 	[%rd4], %r20;
	bar.sync 	0;
	setp.eq.s32 	%p1, %r2, 0;
	@%p1 bra 	$L__BB0_11;

	mad.lo.s32 	%r5, %r3, %r1, %r4;
	shr.u32 	%r22, %r14, 31;
	add.s32 	%r23, %r14, %r22;
	shr.s32 	%r6, %r23, 1;
	mov.u32 	%r35, 2;

$L__BB0_2:
	setp.lt.s32 	%p2, %r35, 2;
	@%p2 bra 	$L__BB0_10;

	shr.u32 	%r36, %r35, 1;
	bra.uni 	$L__BB0_4;

$L__BB0_7:
	setp.le.s32 	%p6, %r10, %r11;
	@%p6 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_8;

$L__BB0_4:
	setp.ge.s32 	%p3, %r5, %r6;
	@%p3 bra 	$L__BB0_9;

	shl.b32 	%r24, %r36, 1;
	div.s32 	%r25, %r5, %r36;
	mul.lo.s32 	%r26, %r25, %r36;
	sub.s32 	%r27, %r5, %r26;
	mad.lo.s32 	%r28, %r24, %r25, %r27;
	xor.b32  	%r29, %r28, %r36;
	and.b32  	%r30, %r28, %r35;
	rem.u32 	%r31, %r28, %r2;
	rem.u32 	%r32, %r29, %r2;
	setp.eq.s32 	%p4, %r30, 0;
	mul.wide.s32 	%rd14, %r31, 4;
	add.s64 	%rd5, %rd11, %rd14;
	ld.shared.u32 	%r10, [%rd5];
	mul.wide.s32 	%rd16, %r32, 4;
	add.s64 	%rd6, %rd11, %rd16;
	ld.shared.u32 	%r11, [%rd6];
	@%p4 bra 	$L__BB0_7;

	setp.lt.s32 	%p5, %r10, %r11;
	@%p5 bra 	$L__BB0_8;
	bra.uni 	$L__BB0_9;

$L__BB0_8:
	st.shared.u32 	[%rd5], %r11;
	st.shared.u32 	[%rd6], %r10;

$L__BB0_9:
	bar.sync 	0;
	shr.u32 	%r36, %r36, 1;
	setp.ne.s32 	%p7, %r36, 0;
	@%p7 bra 	$L__BB0_4;

$L__BB0_10:
	shl.b32 	%r35, %r35, 1;
	setp.le.u32 	%p8, %r35, %r2;
	@%p8 bra 	$L__BB0_2;

$L__BB0_11:
	ld.shared.u32 	%r33, [%rd2];
	st.global.u32 	[%rd1], %r33;
	ld.shared.u32 	%r34, [%rd4];
	st.global.u32 	[%rd3], %r34;
	bar.sync 	0;
	ret;

}
	// .globl	bitonicSortMiddle
.visible .entry bitonicSortMiddle(
	.param .u64 bitonicSortMiddle_param_0,
	.param .u32 bitonicSortMiddle_param_1,
	.param .u32 bitonicSortMiddle_param_2,
	.param .u32 bitonicSortMiddle_param_3
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<20>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd3, [bitonicSortMiddle_param_0];
	ld.param.u32 	%r4, [bitonicSortMiddle_param_2];
	ld.param.u32 	%r5, [bitonicSortMiddle_param_3];
	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r7, %r6, %r8;
	ld.param.u32 	%r9, [bitonicSortMiddle_param_1];
	shr.u32 	%r10, %r9, 31;
	add.s32 	%r11, %r9, %r10;
	shr.s32 	%r12, %r11, 1;
	setp.ge.s32 	%p1, %r1, %r12;
	@%p1 bra 	$L__BB1_5;

	cvta.to.global.u64 	%rd4, %rd3;
	shl.b32 	%r13, %r5, 1;
	div.s32 	%r14, %r1, %r5;
	mul.lo.s32 	%r15, %r14, %r5;
	sub.s32 	%r16, %r1, %r15;
	mad.lo.s32 	%r17, %r13, %r14, %r16;
	xor.b32  	%r18, %r17, %r5;
	and.b32  	%r19, %r17, %r4;
	setp.eq.s32 	%p2, %r19, 0;
	mul.wide.s32 	%rd5, %r17, 4;
	add.s64 	%rd1, %rd4, %rd5;
	ld.global.u32 	%r2, [%rd1];
	mul.wide.s32 	%rd6, %r18, 4;
	add.s64 	%rd2, %rd4, %rd6;
	ld.global.u32 	%r3, [%rd2];
	@%p2 bra 	$L__BB1_3;

	setp.lt.s32 	%p3, %r2, %r3;
	@%p3 bra 	$L__BB1_4;
	bra.uni 	$L__BB1_5;

$L__BB1_4:
	st.global.u32 	[%rd1], %r3;
	st.global.u32 	[%rd2], %r2;

$L__BB1_5:
	ret;

$L__BB1_3:
	setp.le.s32 	%p4, %r2, %r3;
	@%p4 bra 	$L__BB1_5;
	bra.uni 	$L__BB1_4;

}
	// .globl	bitonicSortFinish
.visible .entry bitonicSortFinish(
	.param .u64 bitonicSortFinish_param_0,
	.param .u32 bitonicSortFinish_param_1,
	.param .u32 bitonicSortFinish_param_2
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<33>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd7, [bitonicSortFinish_param_0];
	ld.param.u32 	%r11, [bitonicSortFinish_param_1];
	ld.param.u32 	%r12, [bitonicSortFinish_param_2];
	cvta.to.global.u64 	%rd8, %rd7;
	mov.u32 	%r32, %ntid.x;
	shl.b32 	%r2, %r32, 1;
	mov.u32 	%r3, %ctaid.x;
	mul.lo.s32 	%r13, %r2, %r3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r14, %r13, %r4;
	mul.wide.u32 	%rd9, %r14, 4;
	add.s64 	%rd1, %rd8, %rd9;
	ld.global.u32 	%r15, [%rd1];
	mul.wide.u32 	%rd10, %r4, 4;
	mov.u64 	%rd11, as;
	add.s64 	%rd2, %rd11, %rd10;
	st.shared.u32 	[%rd2], %r15;
	add.s32 	%r16, %r4, %r32;
	add.s32 	%r17, %r16, %r13;
	mul.wide.u32 	%rd12, %r17, 4;
	add.s64 	%rd3, %rd8, %rd12;
	ld.global.u32 	%r18, [%rd3];
	mul.wide.u32 	%rd13, %r16, 4;
	add.s64 	%rd4, %rd11, %rd13;
	st.shared.u32 	[%rd4], %r18;
	bar.sync 	0;
	setp.lt.s32 	%p1, %r32, 1;
	@%p1 bra 	$L__BB2_8;

	mad.lo.s32 	%r5, %r3, %r32, %r4;
	shr.u32 	%r19, %r11, 31;
	add.s32 	%r20, %r11, %r19;
	shr.s32 	%r6, %r20, 1;
	bra.uni 	$L__BB2_2;

$L__BB2_5:
	setp.le.s32 	%p5, %r8, %r9;
	@%p5 bra 	$L__BB2_7;
	bra.uni 	$L__BB2_6;

$L__BB2_2:
	setp.ge.s32 	%p2, %r5, %r6;
	@%p2 bra 	$L__BB2_7;

	shl.b32 	%r21, %r32, 1;
	div.s32 	%r22, %r5, %r32;
	mul.lo.s32 	%r23, %r22, %r32;
	sub.s32 	%r24, %r5, %r23;
	mad.lo.s32 	%r25, %r21, %r22, %r24;
	xor.b32  	%r26, %r25, %r32;
	and.b32  	%r27, %r25, %r12;
	rem.u32 	%r28, %r25, %r2;
	rem.u32 	%r29, %r26, %r2;
	setp.eq.s32 	%p3, %r27, 0;
	mul.wide.s32 	%rd14, %r28, 4;
	add.s64 	%rd5, %rd11, %rd14;
	ld.shared.u32 	%r8, [%rd5];
	mul.wide.s32 	%rd16, %r29, 4;
	add.s64 	%rd6, %rd11, %rd16;
	ld.shared.u32 	%r9, [%rd6];
	@%p3 bra 	$L__BB2_5;

	setp.lt.s32 	%p4, %r8, %r9;
	@%p4 bra 	$L__BB2_6;
	bra.uni 	$L__BB2_7;

$L__BB2_6:
	st.shared.u32 	[%rd5], %r9;
	st.shared.u32 	[%rd6], %r8;

$L__BB2_7:
	bar.sync 	0;
	shr.u32 	%r32, %r32, 1;
	setp.ne.s32 	%p6, %r32, 0;
	@%p6 bra 	$L__BB2_2;

$L__BB2_8:
	ld.shared.u32 	%r30, [%rd2];
	st.global.u32 	[%rd1], %r30;
	ld.shared.u32 	%r31, [%rd4];
	st.global.u32 	[%rd3], %r31;
	bar.sync 	0;
	ret;

}

`
